{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/fs/data/tejasj/anaconda3/envs/rf_tf_torch/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2024-02-05 20:04:01.091534: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-02-05 20:04:01.656545: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2024-02-05 20:04:01.656599: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2024-02-05 20:04:01.656603: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "2024-02-05 20:04:02.343450: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-02-05 20:04:02.343655: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-02-05 20:04:02.347180: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-02-05 20:04:02.347356: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-02-05 20:04:02.347503: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-02-05 20:04:02.347646: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-02-05 20:04:02.351539: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import functools\n",
    "import os\n",
    "import pickle\n",
    "from typing import Any, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from model import DiffWave\n",
    "from omegaconf import OmegaConf\n",
    "from rfcutils2 import qpsk_helper_fn as qpskfn\n",
    "from utils import view_as_complex\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Load the DiffWave QPSK model\n",
    "checkpoint = torch.load(\"../checkpoints/updated/qpsk_100000_160_20_03_09/weights-360000.pt\")\n",
    "cfg_qpsk = OmegaConf.create(checkpoint[\"cfg\"])\n",
    "model_qpsk = DiffWave(cfg_qpsk.model).to(device)\n",
    "model_qpsk.load_state_dict(checkpoint[\"model\"])\n",
    "model_qpsk.eval()\n",
    "\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a colored Gaussian covariance matrix\n",
    "cov_b = pickle.load(open('ofdm_cov.pkl', 'rb'))\n",
    "# Compute the Cholesky decomposition\n",
    "L = np.linalg.cholesky(cov_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new colored Gaussian signal\n",
    "z = (np.random.randn(L.shape[1], 1) + 1j * np.random.randn(L.shape[1], 1)) / np.sqrt(2)\n",
    "w = L @ z\n",
    "w = w.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the interference root directory\n",
    "interference_type = \"qpsk\"\n",
    "qpsk_root_dir = \"../dataset/separation/qpsk/\"\n",
    "b = np.load(os.path.join(qpsk_root_dir, \"sig_200.npy\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "cov_b_tensor = torch.view_as_real(torch.tensor(cov_b, device=device)).float()\n",
    "inv_cov_b_tensor = torch.view_as_real(torch.linalg.inv(torch.tensor(cov_b, device=device))).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def matchedfilter_remod(sig):\n",
    "    b, _ = qpskfn.qpsk_matched_filter_demod(sig)\n",
    "    s, _, _, _ = qpskfn.modulate_qpsk_signal(b)\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def complex_mm(x, y):\n",
    "    # x: (d, d, 2)\n",
    "    # y: (b, 2, d)\n",
    "    real_component = torch.einsum(\"ijl,blj->bi\", x, y * torch.tensor([[1], [-1]], device=device))\n",
    "    imag_component = torch.einsum(\"ijl,blj->bi\", x, torch.flip(y, dims=[1]))\n",
    "    return torch.stack([real_component, imag_component], dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "MIN_STEP, MAX_STEP = 1, 49\n",
    "\n",
    "\n",
    "def args_separation(\n",
    "        mixture: torch.Tensor, \n",
    "        coeff: float, \n",
    "        scaling: float, \n",
    "        num_iters: int, \n",
    "        use_trained_model: bool, \n",
    "        soi: torch.Tensor, \n",
    "        interference: torch.Tensor,\n",
    "        model_interference: torch.nn.Module,\n",
    "        learning_rate_range: Tuple[float, float],\n",
    "        dataset_stats: Tuple[torch.Tensor, torch.Tensor],\n",
    "        device: Any,\n",
    "        **kwargs,\n",
    "):\n",
    "    \"\"\"Perform source separation using \\\\alpha-RGS.\n",
    "\n",
    "    Args:\n",
    "        mixture: Inputs mixture (y = s + \\kappa * b)\n",
    "        coeff: \\kappa\n",
    "        scaling: \\\\alpha-posterior hyperparameter (\\omega)\n",
    "        num_iters: Number of iterations to run \\\\alpha-RGS (N)\n",
    "        use_trained_model: If True, use the learned diffusion model to compute\n",
    "            the SOI score\n",
    "        soi: The SOI (s)\n",
    "        interference: The interference (b)\n",
    "        model_interference: The interference diffusion model\n",
    "        learning_rate_range: Learning rate schedule range (\\eta_max, \\eta_min)\n",
    "        dataset_stats: Dataset mean and standard deviation if interference is \n",
    "            not zero mean and unit variance.\n",
    "    \"\"\"\n",
    "\n",
    "    del kwargs\n",
    "    eta_max, eta_min = learning_rate_range\n",
    "    # Same noise schedule as in our diffusion models. See learner.py\n",
    "    noise_schedule = np.linspace(1e-4, 0.05, 50)\n",
    "    noise_level = torch.tensor(\n",
    "        np.cumprod(1 - noise_schedule).astype(np.float32)\n",
    "    ).to(device)\n",
    "\n",
    "    # Compute the matched filtering solution given the mixture\n",
    "    b_mf = matchedfilter_remod(view_as_complex(coeff * mixture))\n",
    "    b_est = torch.view_as_real(torch.tensor(b_mf.numpy())).transpose(1, 2).float().to(device)\n",
    "    mixture = mixture.to(device)\n",
    "    \n",
    "    for i in range(num_iters):\n",
    "        # Update learning rate using cosine annealing learning rate schedule\n",
    "        eta = eta_min + 0.5 * (eta_max -  eta_min)*(1 + np.cos(np.pi * (i / num_iters)))\n",
    "\n",
    "        # Sample u and 1 - \\alpha_u\n",
    "        t2 = torch.randint(MIN_STEP, max(1, int(MAX_STEP)) + 1, [1], device=device)\n",
    "        noise_scale2 = noise_level[t2]\n",
    "        \n",
    "        noise2 = torch.randn_like(b_est)\n",
    "        \n",
    "        # Apply Gaussian smoothing to the estimate for b\n",
    "        b_est = (b_est - dataset_stats[0]) / dataset_stats[1]\n",
    "        bu_est = noise_scale2 ** 0.5 * b_est.to(device) + (1 - noise_scale2) ** 0.5 * noise2.to(device)\n",
    "        # Apply Gaussian smoothing to the estimates for s\n",
    "        s_est = (mixture * coeff - b_est).to(device)\n",
    "                \n",
    "        # Compute the score of the smoothened interference\n",
    "        sigma2 = (1 - noise_scale2.detach()) ** 0.5 \n",
    "        score_t2 = model_qpsk(bu_est, t2)\n",
    "        score_t2 = score_t2 - noise2.to(device)\n",
    "        score_t2 = -score_t2.detach()/(sigma2)\n",
    "        score_t2 *= (1 - sigma2 ** 2) ** 0.5\n",
    "        \n",
    "        # Compute the score of the SOI\n",
    "        score_t1 = -complex_mm(inv_cov_b_tensor, s_est)\n",
    "        \n",
    "        g = -scaling * score_t2 + score_t1\n",
    "\n",
    "        # Update the estimate using stochastic gradient descent (SGD)\n",
    "        b_est = b_est - eta * g\n",
    "\n",
    "        if (i+1) % 1000  == 0:\n",
    "            b_hat = b_est\n",
    "            s_hat = (mixture * coeff - b_hat)\n",
    "            bit_true, _ = qpskfn.qpsk_matched_filter_demod(view_as_complex(interference))\n",
    "            bit_pred, _ = qpskfn.qpsk_matched_filter_demod(view_as_complex(b_hat.detach().cpu()))\n",
    "            bit_error = np.mean(bit_true != bit_pred)\n",
    "            print(\n",
    "                f\"{i:>4}: - MSE(s_hat-s): {F.mse_loss(soi, s_hat.detach().cpu()):.4f},\"\n",
    "                f\" MSE(b_hat-b): {F.mse_loss(interference, b_hat.detach().cpu()):.6f},\"\n",
    "                f\" BER: {bit_error:.4f}\"\n",
    "            )\n",
    "    return s_est"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "sir_db = -31\n",
    "scaling = \"kappa\"\n",
    "use_trained_model = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiments for metrics/QPSK_ColoredGaussian_aRGS at -31 dB SINR\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 999: - MSE(s_hat-s): 591.2035, MSE(b_hat-b): 1.456908, BER: 0.2219\n",
      "1999: - MSE(s_hat-s): 588.2611, MSE(b_hat-b): 1.404494, BER: 0.2719\n",
      "2999: - MSE(s_hat-s): 585.3636, MSE(b_hat-b): 0.875354, BER: 0.1594\n",
      "3999: - MSE(s_hat-s): 705.5793, MSE(b_hat-b): 23.423038, BER: 0.6813\n",
      "4999: - MSE(s_hat-s): 682.5434, MSE(b_hat-b): 20.907093, BER: 0.5938\n",
      "5999: - MSE(s_hat-s): 595.1469, MSE(b_hat-b): 0.826368, BER: 0.2594\n",
      "6999: - MSE(s_hat-s): 608.6193, MSE(b_hat-b): 0.630489, BER: 0.3000\n",
      "7999: - MSE(s_hat-s): 619.6227, MSE(b_hat-b): 0.700731, BER: 0.3375\n",
      "8999: - MSE(s_hat-s): 620.2085, MSE(b_hat-b): 0.751516, BER: 0.4094\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 1/100 [01:13<2:00:59, 73.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9999: - MSE(s_hat-s): 619.4652, MSE(b_hat-b): 0.745540, BER: 0.4094\n",
      "=================================================\n",
      "SIR [dB] = -31, sample number 0\n",
      "BER (aRSG) = 0.0\n",
      "MSE (aRSG) = 619.4678955078125\n",
      "=================================================\n",
      "\n",
      " 999: - MSE(s_hat-s): 574.5735, MSE(b_hat-b): 3.744415, BER: 0.2062\n",
      "1999: - MSE(s_hat-s): 604.7513, MSE(b_hat-b): 0.717318, BER: 0.2938\n",
      "2999: - MSE(s_hat-s): 616.5256, MSE(b_hat-b): 0.759187, BER: 0.3469\n",
      "3999: - MSE(s_hat-s): 598.0924, MSE(b_hat-b): 0.679680, BER: 0.2406\n",
      "4999: - MSE(s_hat-s): 618.9128, MSE(b_hat-b): 0.512804, BER: 0.3406\n",
      "5999: - MSE(s_hat-s): 597.4986, MSE(b_hat-b): 0.784416, BER: 0.2750\n",
      "6999: - MSE(s_hat-s): 654.2134, MSE(b_hat-b): 1.765303, BER: 0.7969\n",
      "7999: - MSE(s_hat-s): 618.3211, MSE(b_hat-b): 0.586669, BER: 0.3156\n",
      "8999: - MSE(s_hat-s): 619.1688, MSE(b_hat-b): 0.735480, BER: 0.3906\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 2/100 [02:26<2:00:00, 73.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9999: - MSE(s_hat-s): 620.6584, MSE(b_hat-b): 0.765005, BER: 0.3906\n",
      "=================================================\n",
      "SIR [dB] = -31, sample number 1\n",
      "BER (aRSG) = 0.0\n",
      "MSE (aRSG) = 620.6392822265625\n",
      "=================================================\n",
      "\n",
      " 999: - MSE(s_hat-s): 638.8218, MSE(b_hat-b): 1.048312, BER: 0.5563\n",
      "1999: - MSE(s_hat-s): 509.1623, MSE(b_hat-b): 194.778473, BER: 0.2719\n",
      "2999: - MSE(s_hat-s): 597.6239, MSE(b_hat-b): 5.988712, BER: 0.2437\n",
      "3999: - MSE(s_hat-s): 640.1700, MSE(b_hat-b): 2.461205, BER: 0.6125\n",
      "4999: - MSE(s_hat-s): 618.0352, MSE(b_hat-b): 4.489675, BER: 0.4219\n",
      "5999: - MSE(s_hat-s): 718.0197, MSE(b_hat-b): 8.370283, BER: 0.8125\n",
      "6999: - MSE(s_hat-s): 640.2504, MSE(b_hat-b): 1.275588, BER: 0.6625\n",
      "7999: - MSE(s_hat-s): 628.1879, MSE(b_hat-b): 0.965228, BER: 0.4938\n",
      "8999: - MSE(s_hat-s): 618.0627, MSE(b_hat-b): 0.685522, BER: 0.3688\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 3/100 [03:40<1:58:41, 73.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9999: - MSE(s_hat-s): 618.0013, MSE(b_hat-b): 0.674491, BER: 0.3656\n",
      "=================================================\n",
      "SIR [dB] = -31, sample number 2\n",
      "BER (aRSG) = 0.0\n",
      "MSE (aRSG) = 618.0030517578125\n",
      "=================================================\n",
      "\n",
      " 999: - MSE(s_hat-s): 1098.2102, MSE(b_hat-b): 278.049194, BER: 0.7125\n",
      "1999: - MSE(s_hat-s): 677.6078, MSE(b_hat-b): 70.795631, BER: 0.4375\n",
      "2999: - MSE(s_hat-s): 582.1377, MSE(b_hat-b): 1.446971, BER: 0.2062\n",
      "3999: - MSE(s_hat-s): 593.0287, MSE(b_hat-b): 21.293802, BER: 0.3031\n",
      "4999: - MSE(s_hat-s): 672.5695, MSE(b_hat-b): 3.219568, BER: 0.8313\n",
      "5999: - MSE(s_hat-s): 637.4332, MSE(b_hat-b): 1.931159, BER: 0.5938\n",
      "6999: - MSE(s_hat-s): 636.7458, MSE(b_hat-b): 1.174845, BER: 0.5344\n",
      "7999: - MSE(s_hat-s): 655.7150, MSE(b_hat-b): 2.025641, BER: 0.7812\n",
      "8999: - MSE(s_hat-s): 614.3489, MSE(b_hat-b): 0.518503, BER: 0.2531\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 4/100 [04:53<1:57:21, 73.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9999: - MSE(s_hat-s): 610.7971, MSE(b_hat-b): 0.505727, BER: 0.2531\n",
      "=================================================\n",
      "SIR [dB] = -31, sample number 3\n",
      "BER (aRSG) = 0.0\n",
      "MSE (aRSG) = 610.7991943359375\n",
      "=================================================\n",
      "\n",
      " 999: - MSE(s_hat-s): 609.5521, MSE(b_hat-b): 3.956067, BER: 0.2156\n",
      "1999: - MSE(s_hat-s): 1078.9880, MSE(b_hat-b): 105.770020, BER: 0.8469\n",
      "2999: - MSE(s_hat-s): 605.5171, MSE(b_hat-b): 1.805323, BER: 0.2375\n",
      "3999: - MSE(s_hat-s): 675.1791, MSE(b_hat-b): 3.593436, BER: 0.8313\n",
      "4999: - MSE(s_hat-s): 629.6072, MSE(b_hat-b): 0.807379, BER: 0.5188\n",
      "5999: - MSE(s_hat-s): 650.0312, MSE(b_hat-b): 2.413456, BER: 0.6969\n",
      "6999: - MSE(s_hat-s): 614.0875, MSE(b_hat-b): 0.927962, BER: 0.4781\n",
      "7999: - MSE(s_hat-s): 595.8014, MSE(b_hat-b): 0.564726, BER: 0.1875\n",
      "8999: - MSE(s_hat-s): 608.5085, MSE(b_hat-b): 0.444119, BER: 0.2188\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 5/100 [06:07<1:56:15, 73.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9999: - MSE(s_hat-s): 608.2457, MSE(b_hat-b): 0.445949, BER: 0.2188\n",
      "=================================================\n",
      "SIR [dB] = -31, sample number 4\n",
      "BER (aRSG) = 0.0\n",
      "MSE (aRSG) = 608.244140625\n",
      "=================================================\n",
      "\n",
      " 999: - MSE(s_hat-s): 599.5003, MSE(b_hat-b): 29.359314, BER: 0.3406\n",
      "1999: - MSE(s_hat-s): 585.3315, MSE(b_hat-b): 1.990478, BER: 0.2562\n",
      "2999: - MSE(s_hat-s): 596.8706, MSE(b_hat-b): 2.841987, BER: 0.2375\n",
      "3999: - MSE(s_hat-s): 740.6983, MSE(b_hat-b): 11.205671, BER: 0.8406\n",
      "4999: - MSE(s_hat-s): 602.3748, MSE(b_hat-b): 2.733128, BER: 0.3281\n",
      "5999: - MSE(s_hat-s): 610.6661, MSE(b_hat-b): 0.544720, BER: 0.2687\n",
      "6999: - MSE(s_hat-s): 612.9518, MSE(b_hat-b): 0.597298, BER: 0.3063\n",
      "7999: - MSE(s_hat-s): 630.3590, MSE(b_hat-b): 1.041865, BER: 0.6031\n",
      "8999: - MSE(s_hat-s): 627.4375, MSE(b_hat-b): 0.979713, BER: 0.5375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 6/100 [07:20<1:55:02, 73.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9999: - MSE(s_hat-s): 630.5191, MSE(b_hat-b): 1.018485, BER: 0.5375\n",
      "=================================================\n",
      "SIR [dB] = -31, sample number 5\n",
      "BER (aRSG) = 0.0\n",
      "MSE (aRSG) = 630.5215454101562\n",
      "=================================================\n",
      "\n",
      " 999: - MSE(s_hat-s): 572.4474, MSE(b_hat-b): 7.106658, BER: 0.2062\n",
      "1999: - MSE(s_hat-s): 607.4572, MSE(b_hat-b): 113.677307, BER: 0.2969\n",
      "2999: - MSE(s_hat-s): 595.0553, MSE(b_hat-b): 0.537613, BER: 0.1719\n",
      "3999: - MSE(s_hat-s): 607.8254, MSE(b_hat-b): 0.671369, BER: 0.3219\n",
      "4999: - MSE(s_hat-s): 586.8685, MSE(b_hat-b): 0.860537, BER: 0.1781\n",
      "5999: - MSE(s_hat-s): 631.8674, MSE(b_hat-b): 2.050183, BER: 0.4938\n",
      "6999: - MSE(s_hat-s): 613.3995, MSE(b_hat-b): 2.508948, BER: 0.2719\n",
      "7999: - MSE(s_hat-s): 617.2247, MSE(b_hat-b): 0.759779, BER: 0.4000\n",
      "8999: - MSE(s_hat-s): 625.5439, MSE(b_hat-b): 0.843946, BER: 0.4188\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 7/100 [08:33<1:53:50, 73.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9999: - MSE(s_hat-s): 621.7150, MSE(b_hat-b): 0.795175, BER: 0.4188\n",
      "=================================================\n",
      "SIR [dB] = -31, sample number 6\n",
      "BER (aRSG) = 0.0\n",
      "MSE (aRSG) = 621.7175903320312\n",
      "=================================================\n",
      "\n",
      " 999: - MSE(s_hat-s): 617.8499, MSE(b_hat-b): 5.863969, BER: 0.3906\n",
      "1999: - MSE(s_hat-s): 617.2958, MSE(b_hat-b): 0.831463, BER: 0.4531\n",
      "2999: - MSE(s_hat-s): 780.6237, MSE(b_hat-b): 391.167175, BER: 0.1750\n",
      "3999: - MSE(s_hat-s): 578.9606, MSE(b_hat-b): 1.526564, BER: 0.1906\n",
      "4999: - MSE(s_hat-s): 621.1152, MSE(b_hat-b): 1.864521, BER: 0.4594\n",
      "5999: - MSE(s_hat-s): 595.0147, MSE(b_hat-b): 0.693088, BER: 0.2219\n",
      "6999: - MSE(s_hat-s): 621.0622, MSE(b_hat-b): 0.836442, BER: 0.4250\n",
      "7999: - MSE(s_hat-s): 650.0734, MSE(b_hat-b): 1.862998, BER: 0.7219\n",
      "8999: - MSE(s_hat-s): 612.6419, MSE(b_hat-b): 0.572514, BER: 0.3094\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 8/100 [09:47<1:52:38, 73.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9999: - MSE(s_hat-s): 613.4838, MSE(b_hat-b): 0.573251, BER: 0.3094\n",
      "=================================================\n",
      "SIR [dB] = -31, sample number 7\n",
      "BER (aRSG) = 0.0\n",
      "MSE (aRSG) = 613.4862060546875\n",
      "=================================================\n",
      "\n",
      " 999: - MSE(s_hat-s): 626.0618, MSE(b_hat-b): 1.322240, BER: 0.4062\n",
      "1999: - MSE(s_hat-s): 612.3491, MSE(b_hat-b): 2.648165, BER: 0.4125\n",
      "2999: - MSE(s_hat-s): 706.1626, MSE(b_hat-b): 15.990321, BER: 0.7875\n",
      "3999: - MSE(s_hat-s): 614.9687, MSE(b_hat-b): 1.674755, BER: 0.3063\n",
      "4999: - MSE(s_hat-s): 622.4644, MSE(b_hat-b): 1.213125, BER: 0.4313\n",
      "5999: - MSE(s_hat-s): 602.2501, MSE(b_hat-b): 94.572418, BER: 0.2594\n",
      "6999: - MSE(s_hat-s): 605.3418, MSE(b_hat-b): 1.294170, BER: 0.3625\n",
      "7999: - MSE(s_hat-s): 641.8990, MSE(b_hat-b): 1.175771, BER: 0.7188\n",
      "8999: - MSE(s_hat-s): 619.7581, MSE(b_hat-b): 0.663946, BER: 0.3250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 9/100 [11:01<1:51:41, 73.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9999: - MSE(s_hat-s): 614.7031, MSE(b_hat-b): 0.652946, BER: 0.3250\n",
      "=================================================\n",
      "SIR [dB] = -31, sample number 8\n",
      "BER (aRSG) = 0.0\n",
      "MSE (aRSG) = 614.7057495117188\n",
      "=================================================\n",
      "\n",
      " 999: - MSE(s_hat-s): 1214.7600, MSE(b_hat-b): 202.950714, BER: 0.8375\n",
      "1999: - MSE(s_hat-s): 608.7762, MSE(b_hat-b): 1.010314, BER: 0.4375\n",
      "2999: - MSE(s_hat-s): 597.8666, MSE(b_hat-b): 7.934648, BER: 0.3250\n",
      "3999: - MSE(s_hat-s): 595.4943, MSE(b_hat-b): 1.561773, BER: 0.2281\n",
      "4999: - MSE(s_hat-s): 616.0820, MSE(b_hat-b): 0.699530, BER: 0.4188\n",
      "5999: - MSE(s_hat-s): 665.8488, MSE(b_hat-b): 92.421341, BER: 0.3656\n",
      "6999: - MSE(s_hat-s): 609.5904, MSE(b_hat-b): 0.831660, BER: 0.3812\n",
      "7999: - MSE(s_hat-s): 607.6722, MSE(b_hat-b): 0.743667, BER: 0.3281\n",
      "8999: - MSE(s_hat-s): 618.5706, MSE(b_hat-b): 0.789166, BER: 0.4375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 10/100 [12:15<1:50:44, 73.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9999: - MSE(s_hat-s): 623.1461, MSE(b_hat-b): 0.834936, BER: 0.4375\n",
      "=================================================\n",
      "SIR [dB] = -31, sample number 9\n",
      "BER (aRSG) = 0.0\n",
      "MSE (aRSG) = 623.1488647460938\n",
      "=================================================\n",
      "\n",
      " 999: - MSE(s_hat-s): 583.5298, MSE(b_hat-b): 1.385865, BER: 0.2281\n",
      "1999: - MSE(s_hat-s): 781.1377, MSE(b_hat-b): 84.935387, BER: 0.6813\n",
      "2999: - MSE(s_hat-s): 651.9216, MSE(b_hat-b): 30.929987, BER: 0.4500\n",
      "3999: - MSE(s_hat-s): 616.1300, MSE(b_hat-b): 0.665578, BER: 0.2969\n",
      "4999: - MSE(s_hat-s): 588.8362, MSE(b_hat-b): 1.074302, BER: 0.2406\n",
      "5999: - MSE(s_hat-s): 601.9276, MSE(b_hat-b): 0.873642, BER: 0.2281\n",
      "6999: - MSE(s_hat-s): 620.8665, MSE(b_hat-b): 0.884471, BER: 0.5437\n",
      "7999: - MSE(s_hat-s): 634.5305, MSE(b_hat-b): 1.095688, BER: 0.6188\n",
      "8999: - MSE(s_hat-s): 615.8720, MSE(b_hat-b): 0.556390, BER: 0.2687\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 11/100 [13:29<1:49:23, 73.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9999: - MSE(s_hat-s): 611.8992, MSE(b_hat-b): 0.531845, BER: 0.2687\n",
      "=================================================\n",
      "SIR [dB] = -31, sample number 10\n",
      "BER (aRSG) = 0.0\n",
      "MSE (aRSG) = 611.9017944335938\n",
      "=================================================\n",
      "\n",
      " 999: - MSE(s_hat-s): 697.3035, MSE(b_hat-b): 45.002872, BER: 0.6219\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 11/100 [13:41<1:50:44, 74.66s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [44], line 59\u001b[0m\n\u001b[1;32m     56\u001b[0m y \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m/\u001b[39m coeff \u001b[38;5;241m*\u001b[39m soi \u001b[38;5;241m+\u001b[39m interference\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m     58\u001b[0m     \u001b[38;5;66;03m# SOI estimate using source separator\u001b[39;00m\n\u001b[0;32m---> 59\u001b[0m     s_pred \u001b[38;5;241m=\u001b[39m \u001b[43mseparation_fn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     60\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmixture\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     61\u001b[0m \u001b[43m        \u001b[49m\u001b[43msoi\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msoi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     62\u001b[0m \u001b[43m        \u001b[49m\u001b[43minterference\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minterference\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     63\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     64\u001b[0m     s_pred \u001b[38;5;241m=\u001b[39m s_pred\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     66\u001b[0m \u001b[38;5;66;03m# Dump all the results into the output folder\u001b[39;00m\n",
      "Cell \u001b[0;32mIn [42], line 66\u001b[0m, in \u001b[0;36margs_separation\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;66;03m# Compute the score of the smoothened interference\u001b[39;00m\n\u001b[1;32m     65\u001b[0m sigma2 \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m noise_scale2\u001b[38;5;241m.\u001b[39mdetach()) \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m \u001b[38;5;241m0.5\u001b[39m \n\u001b[0;32m---> 66\u001b[0m score_t2 \u001b[38;5;241m=\u001b[39m \u001b[43mmodel_qpsk\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbu_est\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt2\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     67\u001b[0m score_t2 \u001b[38;5;241m=\u001b[39m score_t2 \u001b[38;5;241m-\u001b[39m noise2\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     68\u001b[0m score_t2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39mscore_t2\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m/\u001b[39m(sigma2)\n",
      "File \u001b[0;32m/fs/data/tejasj/anaconda3/envs/rf_tf_torch/lib/python3.10/site-packages/torch/nn/modules/module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1186\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1187\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1188\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/fs/data/tejasj/meta_prior/universal_source_separation/../model.py:120\u001b[0m, in \u001b[0;36mDiffWave.forward\u001b[0;34m(self, input, diffusion_step)\u001b[0m\n\u001b[1;32m    118\u001b[0m skip \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    119\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresidual_layers:\n\u001b[0;32m--> 120\u001b[0m     x, skip_connection \u001b[38;5;241m=\u001b[39m \u001b[43mlayer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdiffusion_step\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    121\u001b[0m     skip \u001b[38;5;241m=\u001b[39m skip_connection \u001b[38;5;28;01mif\u001b[39;00m skip \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m skip_connection \u001b[38;5;241m+\u001b[39m skip\n\u001b[1;32m    123\u001b[0m x \u001b[38;5;241m=\u001b[39m skip \u001b[38;5;241m/\u001b[39m sqrt(\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresidual_layers))\n",
      "File \u001b[0;32m/fs/data/tejasj/anaconda3/envs/rf_tf_torch/lib/python3.10/site-packages/torch/nn/modules/module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1186\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1187\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1188\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/fs/data/tejasj/meta_prior/universal_source_separation/../model.py:88\u001b[0m, in \u001b[0;36mResidualBlock.forward\u001b[0;34m(self, x, diffusion_step)\u001b[0m\n\u001b[1;32m     86\u001b[0m y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_projection(y)\n\u001b[1;32m     87\u001b[0m residual, skip \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mchunk(y, \u001b[38;5;241m2\u001b[39m, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m---> 88\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m (x \u001b[38;5;241m+\u001b[39m residual) \u001b[38;5;241m/\u001b[39m \u001b[43msqrt\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m2.0\u001b[39;49m\u001b[43m)\u001b[49m, skip\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Load the inference dataset and pre-trained diffusion models\n",
    "if interference_type == \"commsignal2\":\n",
    "    dataset_mean = torch.tensor(\n",
    "        np.array([ 1.3608e-05, -1.5107e-06]).reshape(1, 2, 1)\n",
    "    ).float()\n",
    "    dataset_std =  torch.tensor(\n",
    "        np.array([0.7634, 0.7634]).reshape(1, 2, 1)\n",
    "    ).float()\n",
    "else:\n",
    "    dataset_mean = torch.zeros(1, 2, 1)\n",
    "    dataset_std = torch.ones(1, 2, 1)\n",
    "\n",
    "# Set the value of \\kappa\n",
    "coeff = np.sqrt(10 ** (-sir_db / 10))\n",
    "if \"ofdm\" in interference_type:\n",
    "    # Only used for plotting, not required for source separation\n",
    "    coeff = coeff * np.sqrt(64/56)  # 56/64 is the compensating power for OFDM\n",
    "\n",
    "# Set the value of \\alpha-posterior parameter \\alpha=\\omega\n",
    "scaling_str = scaling\n",
    "use_alpha_posterior = False\n",
    "if isinstance(scaling, str):\n",
    "    if scaling == \"invkappa\":\n",
    "        scaling = 1 / coeff\n",
    "    elif scaling == \"kappa\":\n",
    "        scaling = coeff\n",
    "        use_alpha_posterior = True\n",
    "    else:\n",
    "        raise ValueError(\"Unexpected string identifier for scaling value.\")\n",
    "\n",
    "separation_fn = functools.partial(\n",
    "    args_separation,\n",
    "    coeff=coeff,\n",
    "    scaling=scaling,\n",
    "    num_iters=10000,\n",
    "    use_trained_model=use_trained_model,\n",
    "    model_interference=model_qpsk,\n",
    "    cfg_interference=cfg_qpsk,\n",
    "    learning_rate_range=[5e-3, 1e-6],\n",
    "    dataset_stats=(dataset_mean.to(device), dataset_std.to(device)),\n",
    "    use_alpha_posterior=use_alpha_posterior,\n",
    "    device=device,\n",
    ")\n",
    "\n",
    "# Create an output file to save results \n",
    "output_folder = \"metrics/QPSK_ColoredGaussian_aRGS\"\n",
    "if not os.path.exists(output_folder):\n",
    "    os.makedirs(output_folder)\n",
    "print(f\"Experiments for {output_folder} at {sir_db} dB SINR\")\n",
    "\n",
    "interference = torch.view_as_real(torch.tensor(b)).transpose(0, 1).float().unsqueeze(0)\n",
    "soi = torch.view_as_real(torch.tensor(w)).transpose(0, 1).float().unsqueeze(0)\n",
    "\n",
    "# Normalize the mixture by \\kappa, i.e., y / \\kappa\n",
    "y = 1 / coeff * soi + interference\n",
    "with torch.no_grad():\n",
    "    # SOI estimate using source separator\n",
    "    s_pred = separation_fn(\n",
    "        mixture=y, \n",
    "        soi=soi, \n",
    "        interference=interference,\n",
    "    )\n",
    "    s_pred = s_pred.to(device)\n",
    "\n",
    "# Dump all the results into the output folder\n",
    "pickle.dump(\n",
    "    (y, soi, interference, s_pred), \n",
    "    open(f\"{output_folder}/sample_{sir_db}dB_{idx}.pkl\",\"wb\")\n",
    ")\n",
    "\n",
    "bit_true, _ = qpskfn.qpsk_matched_filter_demod(view_as_complex(interference.cpu()))\n",
    "bit_pred, _ = qpskfn.qpsk_matched_filter_demod(view_as_complex(s_pred.cpu()))\n",
    "\n",
    "print(\"=================================================\")\n",
    "print(f\"SIR [dB] = {sir_db}, sample number {idx - 100}\")\n",
    "print(f\"BER (aRSG) = {np.mean(bit_true != bit_pred)}\")\n",
    "print(f\"MSE (aRSG) = {F.mse_loss(soi, s_pred.detach().cpu()).numpy()}\")\n",
    "print(\"=================================================\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
